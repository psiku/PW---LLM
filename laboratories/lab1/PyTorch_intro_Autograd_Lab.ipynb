{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY88NuVprDxy"
      },
      "source": [
        "#PyTorch Intro - Autoróżniczkowanie i Graf Obliczeń - Laboratorium\n",
        "\n",
        "Do optymalizacji parametrów (wag) sieci neuronowej podczas treningu modelu wykorzystuje się **metodę stochastycznego spadku wzdłuż gradientu**.\n",
        "Gradient funkcji straty względem parametrów sieci wyznaczany jest algorytmem **propagacji wstecznej** (*back propagation*).\n",
        "\n",
        "Sieć neuronową możemy potraktować jak złożoną funkcję mapującą wejściowe dane $x \\in \\mathcal{X}$ (np. obraz czy sekwencję audio) na wyjście $y \\in \\mathcal{Y}$ parametryzowaną zestawem parametrów (wag) $\\theta$.\n",
        "$$\n",
        "f_{\\theta}( x ) = y\n",
        "$$\n",
        "W przypadku $n$-klasowego klasyfikatora wyjściem z sieci jest wektor $y \\in \\mathbb{R}^n$ nieznormalizowanych wartości, zwanych logitami, z których możemy wyznaczyć rozkład prawdopodobieństwa klas korzystając z funkcji softmax.\n",
        "\n",
        "W jednym kroku treningu sieci neuronowych wykonujemy:\n",
        "1. **Przejście w przód** - przetworzenie zestawu wejściowych danych treningowych przez sieć i wyznaczenie wartości wynikowych $y = f_{\\theta}(x)$. Następnie wyznaczenie wartości funkcji straty\n",
        "$\\mathcal{L}$\n",
        "w oparciu o wynikową wartość z sieci i prawdziwą (docelową) wartość.\n",
        "2. **Przejście w tył** (propagacja wsteczna) - wyznaczenie **gradientu funkcji  straty** $\\mathcal{L}$ **względem parametrów sieci** $\\theta$.\n",
        "3. Krok optymalizacji parametrów sieci - zmiana w kierunku przeciwnym do gradientu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ6auP2WCnLW"
      },
      "source": [
        "##Przygotowanie środowiska\n",
        "Upewnij się, że notatnik jest uruchomiony na maszynie z GPU. Jeśli GPU nie jest dostępne zmień typ maszyny (Runtime | Change runtime type) i wybierz T4 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfwBYOmmnw0b"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1G8i4wTrfq6"
      },
      "source": [
        "Biblioteka PyTorch (`torch`) jest domyślnie zainstalowana w środowisku COLAB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDGaiuGLrapP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(f\"Wersja biblioteki PyTorch: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ6c3h4nryQJ"
      },
      "source": [
        "Sprawdzenie dostępnego urządzenia GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGyMG3_2rxIC"
      },
      "outputs": [],
      "source": [
        "print(f\"Dostępność GPU: {torch.cuda.is_available()}\")\n",
        "print(f\"Typ GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalacja pakietu torchviz do wizualizacji grafów obliczeń ([link](https://github.com/szagoruyko/pytorchviz))."
      ],
      "metadata": {
        "id": "JrekpMsKcafs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchviz"
      ],
      "metadata": {
        "id": "SzkIy9W8cZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cazrrG01sbUH"
      },
      "source": [
        "#Automatyczne różniczkowanie (`torch.autograd`)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient** (lub gradientowe pole wektorowe) funkcji skalarnej wielu zmiennych $\n",
        "f: \\mathbb{R}^D → \\mathbb{R}\n",
        "$ oznaczamyy\n",
        "$\\nabla f$ (czytaj: nabla).\n",
        "W układzie współrzędnych kartezjańskich gradient jest wektorem, którego składowe są pochodnymi cząstkowymi funkcji $f$:\n",
        "$$\\nabla f=\\left[{\\frac {\\partial f}{\\partial x_{1}}},\\dots ,{\\frac {\\partial f}{\\partial x_{n}}}\\right]$$\n",
        "\n",
        "Niech $\\mathcal{L}: \\mathbb{R}^D \\rightarrow \\mathbb{R}$ będzie pewną funkcją straty określoną dla sieci neuronowej o $D$ parametrach (wagach).\n",
        "Celem treningu sieci neuronowej jest znalezienie zestawu parametrów $\\mathbf{\\hat{}} \\in \\mathbb{R}^D$ minimalizującego wartośc funkcji straty:\n",
        "$$\\mathbf{\\hat{w}} = \\arg \\min_{\\textbf{w}} \\mathcal{L} \\left( \\textbf{w} \\right)$$\n",
        "W metodzie **spadku wzdłuż gradientu** zaczynamy od losowo zainicjalizowanych parametrów (wag) sieci $\\textbf{w}_0$ a następnie iteracyjnie aktualizujemy parametry sieci w kierunku przeciwnym do wartości gradientu:\n",
        "$$\n",
        "\\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\eta \\nabla \\mathcal{L} \\left( \\mathbf{w}_t \\right)\n",
        "$$.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G1OdCLSqaaj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby wyznaczyć **gradient funkcji straty względem parametrów sieci**, PyTorch posiada wbudowany mechanizm różniczkowania o nazwie `torch.autograd`. Umożliwia on automatyczne obliczanie gradientu dla dowolnego grafu obliczeniowego.\n",
        "\n",
        "Obiekty typu Tensor posiadają logiczną flagę `requires_grad`.\n",
        "Domyślnie flaga `requires_grad` jest ustawiana na `False`.\n",
        "Po jej włączeniu PyTorch będzie automatycznie budował grafy dla wszystkich obliczeń wykonanych z wykorzystaniem tego tensora aby umożliwić automatyczne wyznaczanie gradientu.\n",
        "Jeśli jeden z argumentów operacji na tensorach ma ustawioną flagę `requires_grad`, wynik również będzie miał ustawioną tę flagę."
      ],
      "metadata": {
        "id": "bWXwwnMI2Eqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zadania do wykonania"
      ],
      "metadata": {
        "id": "cmzWqy6-mLe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zadanie 1\n",
        "\n",
        "Niech $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ będzie funkcją:\n",
        "\n",
        "$$f(x) = sin(x_1) cos(x_2) + sin(0.5 \\cdot x_1) cos(0.5 \\cdot x_2)$$.\n",
        "\n",
        "1.   Napisz kod wyznaczających lokalne minimum funkcji $f$ metodą spadku wzdłuż gradientu dla początkowych wartości argumentów $x_1, x_2$ wylosowanych z zakresu $[0; 10]$. Wyświetl znalezione minimum oraz wartości argumentów funcji.\n",
        "    *   Wykorzystaj mechanizm autoróżniczkowania do wyznaczenia gradientu funkcji $f$. Pamiętaj, aby włączyć budowanie grafu obliczeń dla tensorów `x1` i `x2`.\n",
        "    *   Liczbę iteracji i stopę uczenia dobierz eksperymentalnie.\n",
        "    *   Na końcu każdego kroku optymalizacji wyzeruj wartości gradientów każdego z argumentów (`x.grad.zeros_()`). Domyślnie PyTorch akumuluje wartości gradientu dla wielu wywołań przejścia w tył `backward()`.\n",
        "2.   Zwizualizuj trajektorie parametrów $(x_1, x_2)$ w kolejnych krokach optymalizacji powtarzając cały proces kilkakrotnie, rozpoczynając od losowo wybranych wartości argumentów, każdy z zakresu $[0; 10]$. Czy za każdym razem osiągane jest to samo lokalne minimum?\n",
        "3.   (opcjonalnie) Zaimplementuj zwektoryzowaną wersję procedury wykonującej minimalizację wartości funkcji $f$ dla wielu zestawów argumentów wejściowych danych jako macierz (tensor) o wymiarach $(n,2)$.\n",
        "   *   Zwektoryzowana wersja nie zawiera pętli przechodzącej po każdym z $n$ zestawów argumentów. W jednym kroku optymalizacji aktualizuje wszystkie $n$ zestawów argumentów.\n",
        "   *   Aby wyznaczyć gradient dla każdego elementu z osobna tensora który nie jest skalarem, np. dla $n$-elementowego wektora `f` zawierającego wyniki obliczeń dla $n$ zestawów argumentów, jako argument metody `backward` podaj tensor jedynek o rozmiarze równym rozmiarowi `f`, np. `f.backward(torch.ones_like(f))`."
      ],
      "metadata": {
        "id": "4EZmRI1NmQMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wizualizacja funkcji $f(x)$ z wykorzystaniem biblioteki Plotly."
      ],
      "metadata": {
        "id": "U8Owe56cFXuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Utwórz siatkę wartości x i y\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.linspace(0, 10, 100)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = np.sin(X) * np.cos(Y) + np.sin(0.5 * X) * np.cos(0.5 * Y)\n",
        "\n",
        "fig = go.Figure(data=go.Contour(z=Z, x=x, y=y, colorscale='Viridis'))\n",
        "fig.update_layout(title=\"Izolinie funkcji 3D\", xaxis_title=\"X\", yaxis_title=\"Y\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8eN2-BI2E_Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure(data=[go.Surface(z=Z, x=x, y=y, colorscale='Viridis')])\n",
        "fig.update_layout(\n",
        "    scene=dict(xaxis_title=\"X\", yaxis_title=\"Y\", zaxis_title=\"Z\")\n",
        "    )\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KEPNpW7vFJkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8dTMXRuEE_ND"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}